import asyncio
import logging
from typing import Optional, List
import socket
import sys
import os
import json

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))
from database import db_config_var, supabase_client_var

# ê°™ì€ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ì„ ì„í¬íŠ¸
from .start_multi_format import run_multi_format_generation  # main_multi_format.pyê°€ ì•„ë‹Œ start_multi_format.pyë¥¼ ì‚¬ìš©
from .context_manager import context_manager
import psycopg2
from psycopg2.extras import RealDictCursor

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("todolist_poller")
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

# ğŸ¯ ìˆœì„œ ê´€ë¦¬ ì‹œìŠ¤í…œ
order_system = {}  # {proc_inst_id: {ì•¡í‹°ë¹„í‹°_id: ë²ˆí˜¸, í˜„ì¬_ìˆœì„œë²ˆí˜¸: 0}}
waiting_queue = {}  # {proc_inst_id: [ëŒ€ê¸°ì¤‘ì¸ todolist í•­ëª©ë“¤]}

def update_order_system(rows: List[dict], proc_def_rows: List[dict]):
    """
    ìˆœì„œ ì‹œìŠ¤í…œì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    proc_def_idë¡œ ìˆœì„œ ì •ë³´ë§Œ ê°€ì ¸ì™€ì„œ ë°”ë¡œ proc_inst_idë¥¼ í‚¤ë¡œ ì €ì¥
    """
    global order_system
    
    # proc_def_idë³„ë¡œ definition ë§¤í•‘
    proc_def_map = {row['id']: row['definition'] for row in proc_def_rows}
    
    # ìƒˆë¡œìš´ proc_inst_idë“¤ì— ëŒ€í•´ ìˆœì„œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    for row in rows:
        proc_inst_id = row.get('proc_inst_id')
        proc_def_id = row.get('proc_def_id')
        
        if proc_inst_id not in order_system:
            # proc_def_idë¡œ ìˆœì„œ ì •ë³´ ê°€ì ¸ì™€ì„œ ë°”ë¡œ proc_inst_idì— ì €ì¥
            if proc_def_id in proc_def_map:
                try:
                    definition_str = proc_def_map[proc_def_id]
                    definition = json.loads(definition_str) if isinstance(definition_str, str) else definition_str
                    sequences = definition.get('sequences', [])
                    
                    # ğŸ” sequences ì „ì²´ ë‚´ìš© í™•ì¸
                    print(f"[sequences] {[s.get('target') for s in sequences]}")
                    
                    # sequencesì—ì„œ target ìˆœì„œ ì¶”ì¶œ (ê²Œì´íŠ¸ì›¨ì´ ì œì™¸ + ì¤‘ë³µ ì œê±°)
                    order_info = {'í˜„ì¬_ìˆœì„œë²ˆí˜¸': 0}
                    order_index = 0
                    seen_activities = set()
                    
                    for i, seq in enumerate(sequences):
                        target = seq.get('target')
                        if target and not target.startswith('gateway_'):  # ê²Œì´íŠ¸ì›¨ì´ ì œì™¸
                            if target not in seen_activities:  # ğŸ¯ ì¤‘ë³µ ì œê±°
                                order_info[target] = order_index
                                seen_activities.add(target)
                                print(f"[filtered] {i} -> {target} (ìˆœì„œ: {order_index})")
                                order_index += 1
                            else:
                                print(f"[duplicate] {i} -> {target} (ì´ë¯¸ ì¡´ì¬, ê±´ë„ˆëœ€)")
                        elif target:
                            print(f"[gateway] {i} -> {target} (ê±´ë„ˆëœ€)")
                    
                    order_system[proc_inst_id] = order_info
                    
                    # ğŸ¯ ì´ ìˆœì„œë„ ì¶œë ¥
                    activity_order_log = [f"{activity_id}:{order_num}" for activity_id, order_num in order_info.items() if activity_id != 'í˜„ì¬_ìˆœì„œë²ˆí˜¸']
                    print(f"[ìˆœì„œë„] {', '.join(activity_order_log)}")
                    
                except (json.JSONDecodeError, KeyError) as e:
                    order_system[proc_inst_id] = {'í˜„ì¬_ìˆœì„œë²ˆí˜¸': 0}
            else:
                order_system[proc_inst_id] = {'í˜„ì¬_ìˆœì„œë²ˆí˜¸': 0}
                
            # ëŒ€ê¸° íë„ ì´ˆê¸°í™”
            if proc_inst_id not in waiting_queue:
                waiting_queue[proc_inst_id] = []

def can_process_now(item: dict) -> bool:
    """
    í˜„ì¬ í•­ëª©ì´ ì²˜ë¦¬ ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    proc_inst_id = item.get('proc_inst_id')
    activity_id = item.get('activity_id')
    
    if proc_inst_id not in order_system:
        return False
    
    current_order = order_system[proc_inst_id].get('í˜„ì¬_ìˆœì„œë²ˆí˜¸', 0)
    activity_order = order_system[proc_inst_id].get(activity_id, 999)
    
    return current_order == activity_order

def is_last_order(proc_inst_id: str) -> bool:
    """
    í˜„ì¬ ìˆœì„œê°€ ë§ˆì§€ë§‰ ìˆœì„œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    if proc_inst_id not in order_system:
        return False
    
    current_order = order_system[proc_inst_id].get('í˜„ì¬_ìˆœì„œë²ˆí˜¸', 0)
    
    # ëª¨ë“  ì•¡í‹°ë¹„í‹°ì˜ ìˆœì„œë²ˆí˜¸ ì¤‘ ìµœëŒ€ê°’ ì°¾ê¸°
    max_order = -1
    for key, value in order_system[proc_inst_id].items():
        if key != 'í˜„ì¬_ìˆœì„œë²ˆí˜¸' and isinstance(value, int):
            max_order = max(max_order, value)
    
    return current_order == max_order

def advance_order(proc_inst_id: str):
    """
    í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ì˜ ìˆœì„œë¥¼ ë‹¤ìŒìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    """
    if proc_inst_id in order_system:
        # ğŸ¯ advance í•˜ê¸° ì „ì— í˜„ì¬ê°€ ë§ˆì§€ë§‰ì¸ì§€ ì²´í¬
        current_order = order_system[proc_inst_id]['í˜„ì¬_ìˆœì„œë²ˆí˜¸']
        is_last = is_last_order(proc_inst_id)
        
        if is_last:
            # ğŸ¯ ë©”ëª¨ë¦¬ ì •ë¦¬: ì™„ë£Œëœ í”„ë¡œì„¸ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì œê±°
            if proc_inst_id in order_system:
                del order_system[proc_inst_id]
            
            if proc_inst_id in waiting_queue:
                del waiting_queue[proc_inst_id]
                
        else:
            # ìˆœì„œ ì§„í–‰
            order_system[proc_inst_id]['í˜„ì¬_ìˆœì„œë²ˆí˜¸'] += 1

def add_to_waiting_queue(item: dict):
    """
    ëŒ€ê¸° íì— í•­ëª©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    proc_inst_id = item.get('proc_inst_id')
    if proc_inst_id not in waiting_queue:
        waiting_queue[proc_inst_id] = []
    
    # ì¤‘ë³µ ë°©ì§€
    if not any(existing['id'] == item['id'] for existing in waiting_queue[proc_inst_id]):
        waiting_queue[proc_inst_id].append(item)

def check_waiting_queue() -> List[dict]:
    """
    ëŒ€ê¸° íì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥í•œ í•­ëª©ë“¤ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    ready_items = []
    
    for proc_inst_id, items in waiting_queue.items():
        items_to_remove = []
        
        for item in items:
            if can_process_now(item):
                ready_items.append(item)
                items_to_remove.append(item)
        
        # ì²˜ë¦¬ ê°€ëŠ¥í•œ í•­ëª©ë“¤ì„ ëŒ€ê¸° íì—ì„œ ì œê±°
        for item in items_to_remove:
            waiting_queue[proc_inst_id].remove(item)
    
    return ready_items

async def fetch_pending_todolist(limit: int = 10) -> Optional[List[dict]]:
    """
    ğŸ¯ í•µì‹¬: ìˆœì„œ ê´€ë¦¬ ì‹œìŠ¤í…œì„ í†µí•œ ì²´ê³„ì ì¸ ì²˜ë¦¬
    """
    try:
        db_config = db_config_var.get()
        connection = psycopg2.connect(**db_config)
        cursor = connection.cursor(cursor_factory=RealDictCursor)

        # ğŸ¯ ê°„ë‹¨í•œ ë°©ì‹: draft = {} ì„¤ì •ìœ¼ë¡œ ì„ ì 
        query = """
            UPDATE todolist 
            SET draft = '{}'
            WHERE id IN (
                SELECT id FROM todolist 
                WHERE draft IS NULL 
                LIMIT %s
            )
            RETURNING *;
        """
        cursor.execute(query, (limit,))
        rows = cursor.fetchall()
        connection.commit()
        
        if not rows:
            cursor.close()
            connection.close() 
            # ëŒ€ê¸° íë§Œ í™•ì¸
            ready_from_queue = check_waiting_queue()
            return ready_from_queue if ready_from_queue else None

        # 2ë‹¨ê³„: proc_def ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        proc_def_ids = list(set([row.get('proc_def_id') for row in rows if row.get('proc_def_id')]))
        
        proc_def_query = """
            SELECT id, definition FROM proc_def
            WHERE id = ANY(%s)
        """
        cursor.execute(proc_def_query, (proc_def_ids,))
        proc_def_rows = cursor.fetchall()
        
        cursor.close()
        connection.close()
        
        # 3ë‹¨ê³„: ìˆœì„œ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
        update_order_system(rows, proc_def_rows)
        
        # 4ë‹¨ê³„: ì²˜ë¦¬ ê°€ëŠ¥í•œ í•­ëª©ê³¼ ëŒ€ê¸° í•­ëª© ë¶„ë¥˜
        ready_items = []
        
        for item in rows:
            if can_process_now(item):
                ready_items.append(item)
            else:
                add_to_waiting_queue(item)
        
        # 5ë‹¨ê³„: ëŒ€ê¸° íì—ì„œë„ ì²˜ë¦¬ ê°€ëŠ¥í•œ í•­ëª© í™•ì¸
        ready_from_queue = check_waiting_queue()
        ready_items.extend(ready_from_queue)
        

        
        return ready_items[:limit] if ready_items else None

    except Exception as e:
        logger.error(f"DB fetch failed: {str(e)}")
        return None

async def handle_todolist_item(item: dict, is_first_item: bool = False):
    """
    ê°œë³„ todolist í•­ëª©ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    tool í•„ë“œì—ì„œ formHandler: ì ‘ë‘ì–´ë¥¼ ì œê±°í•˜ê³  form_def í…Œì´ë¸”ì—ì„œ fields_jsonì„ ê°€ì ¸ì™€ ì²˜ë¦¬ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        logger.info(f"Processing todolist item: {item['id']} (first_item: {is_first_item})")

        # Supabase í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        supabase = supabase_client_var.get()
        if supabase is None:
            raise Exception("Supabase client is not configured")

        # ì •ë ¬ëœ ì²«ë²ˆì§¸ í•­ëª©(ìˆœì„œ 0)ë§Œ output í•„ë“œ ì§ì ‘ ì €ì¥
        if is_first_item:
            output_data = item.get('output', {})
            
            # context_managerì— ì €ì¥
            if item.get('proc_inst_id') and item.get('activity_name'):
                context_manager.save_context(
                    proc_inst_id=item.get('proc_inst_id'),
                    activity_name=item.get('activity_name'),
                    content=output_data
                )
            
            # todolist ì™„ë£Œ ì²˜ë¦¬ (draftì—ëŠ” ë¹ˆ JSON ê°ì²´ ì €ì¥)
            supabase.table('todolist').update({
                'draft': {}  # ì²« ë²ˆì§¸ í•­ëª©ì€ ë¹ˆ JSON ê°ì²´
            }).eq('id', item['id']).execute()
            
            # ğŸ¯ ìˆœì„œ ì§„í–‰
            advance_order(item.get('proc_inst_id'))
            return

        # 1ë²ˆì§¸ ì´í›„ ìˆœì„œëŠ” ê¸°ì¡´ AI ì²˜ë¦¬ ë¡œì§ ìˆ˜í–‰
        # tool í•„ë“œì—ì„œ formHandler: ì œê±°í•˜ì—¬ form_def id ì¶”ì¶œ
        tool_value = item.get('tool', '') or ''
        form_id = tool_value[12:] if tool_value.startswith('formHandler:') else tool_value

        # user_info ì¡°íšŒ: emailë¡œ username ê²€ìƒ‰
        user_email = item.get('user_id')
        user_resp = supabase.table('users').select('username').eq('email', user_email).execute()
        user_name = user_resp.data[0]['username'] if user_resp.data and len(user_resp.data) > 0 else None
        user_info = {
            'email': user_email,
            'name': user_name,
            'department': 'ì¸ì‚¬íŒ€',  # í•˜ë“œì½”ë”©
            'position': 'ì‚¬ì›'      # í•˜ë“œì½”ë”©
        }

        # form_defì—ì„œ fields_json ì¡°íšŒ
        response = supabase.table('form_def').select('fields_json').eq('id', form_id).execute()
        fields_json = None
        if response.data and len(response.data) > 0:
            fields_json = response.data[0].get('fields_json')

        # ìƒˆë¡œìš´ ì½”ë“œ
        form_types = []
        if fields_json:
            for field in fields_json:
                field_type = field.get('type', '').lower()
                # textareaë„ textë¡œ ê°„ì£¼
                if field_type in ['report', 'slide', 'text', 'textarea']:
                    normalized_type = 'text' if field_type == 'textarea' else field_type
                    form_types.append({
                        'id': field.get('key'),
                        'type': normalized_type,
                        'key': field.get('key'),
                        'text': field.get('text', '')
                    })

        # ë§Œì•½ form_typesê°€ ë¹„ì–´ìˆë‹¤ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
        if not form_types:
            form_types = [{'id': form_id, 'type': 'default'}]


        # MultiFormatFlow ì‹¤í–‰ (fields_json ë° user_info, todo_id, form_id ì „ë‹¬)
        result = await run_multi_format_generation(
            topic=item.get('activity_name', ''),
            form_types=form_types,
            user_info=user_info,
            todo_id=item.get('id'),
            proc_inst_id=item.get('proc_inst_id'),
            form_id=form_id  # "formHandler:" ì ‘ë‘ì–´ê°€ ì œê±°ëœ ì‹¤ì œ form_def id
        )
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ draft ì—…ë°ì´íŠ¸
        supabase.table('todolist').update({
            'draft': result
        }).eq('id', item['id']).execute()
        
        # ğŸ¯ ìˆœì„œ ì§„í–‰
        advance_order(item.get('proc_inst_id'))

    except Exception as e:
        logger.error(f"Error handling todolist item {item['id']}: {str(e)}")
        # ğŸ¯ ì—ëŸ¬ ë°œìƒ ì‹œ draftë¥¼ NULLë¡œ ë˜ëŒë ¤ì„œ ì¬ì²˜ë¦¬ ê°€ëŠ¥í•˜ê²Œ í•¨
        try:
            supabase = supabase_client_var.get()
            if supabase:
                supabase.table('todolist').update({
                    'draft': None
                }).eq('id', item['id']).execute()
        except Exception as cleanup_error:
            logger.error(f"Error cleaning up draft for item {item['id']}: {str(cleanup_error)}")

async def todolist_polling_task():
    """
    todolist í…Œì´ë¸”ì„ ì£¼ê¸°ì ìœ¼ë¡œ í´ë§í•˜ëŠ” íƒœìŠ¤í¬
    """
    while True:
        try:
            items = await fetch_pending_todolist()
            if items:
                for item in items:
                    # í˜„ì¬ ìˆœì„œ í™•ì¸
                    proc_inst_id = item.get('proc_inst_id')
                    current_order = order_system.get(proc_inst_id, {}).get('í˜„ì¬_ìˆœì„œë²ˆí˜¸', 0)
                    is_first_item = current_order == 0
                    
                    # ğŸ¯ í˜„ì¬ë²ˆí˜¸ì™€ ì•¡í‹°ë¹„í‹°ì´ë¦„ ì¶œë ¥
                    print(f"[ì²˜ë¦¬] í˜„ì¬ë²ˆí˜¸: {current_order}, ì•¡í‹°ë¹„í‹°: {item.get('activity_name')}")
                    
                    await handle_todolist_item(item, is_first_item)
            
            await asyncio.sleep(15)
            
        except Exception as e:
            logger.error(f"Polling error: {str(e)}")
            await asyncio.sleep(15) 